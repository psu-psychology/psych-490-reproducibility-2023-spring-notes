[["index.html", "PSYCH 490.002 Spring 2023 notes About", " PSYCH 490.002 Spring 2023 notes Rick O. Gilmore, Ph.D. 2023-01-12 About These lecture notes are for your use as a student in PSYCH 490.002. "],["course-intro.html", "Topic 1 Course intro Prelude Today’s Topics Introductions Course overview Resources Themes/topics Structure Assignments &amp; evaluation Are we (scientists, the public) fooling ourselves? How can we know? Why might it matter? Learn more Next time…", " Topic 1 Course intro Prelude I like to have a series of songs or videos ready to play before class begins. They are loosely related to some of the themes of the course that day. Most are songs or artists I like. Showing them is just for fun. Today’s Topics Introductions Course overview Are we (scientists, the public) fooling ourselves? How can we know? Why might it matter? Introductions Teaching Assistant Garrett Thomas. M.S. gat84 AT-SIGN psu PERIOD edu Professor Rick O. Gilmore, Ph.D. Professor of Psychology Figure 1.1: https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/DenverCP.JPG/266px-DenverCP.JPG Figure 1.2: http://watson.brown.edu/ds/sites/all/themes/ds/img/header/brown_large.png Figure 1.3: https://www.wheretraveler.com/sites/default/files/styles/wt17_promoted/public/WashingtonDC-shutterstock_93633676.jpg?itok=IT7CL9PU Figure 1.4: https://ai.cs.cmu.edu/sites/default/files/CMU.png Figure 1.5: http://onwardstate.com/wp-content/uploads/2014/10/93 Figure 1.6: https://imaging.psu.edu Figure 1.7: https://nyu.databrary.org/web/images/logo/databrary-nav.svg Course overview Resources Themes/topics Structure Assignments/evaluation Resources Websites Syllabus: https://psu-psychology.github.io/psych-490-reproducibility-2023-spring/ Class notes: https://psu-psychology.github.io/psych-490-reproducibility-2023-spring-notes/ Book Other readings Book selections Scanned PDFs of book selections are available on Canvas: https://psu.instructure.com/courses/2245007/files/folder/readings Articles Retrieve them yourself via the URL (uniform resource locator) and the DOI (digital object identifier). Why do I do this? Themes/topics What is science trying to do? What practices and norms constitute better science? What practices and norms constitute poorer science? Is there a crisis of reproducibility or replicability in psychological science? Is there a crisis in other areas of science? What are scientists doing to address these criticisms? Structure Meet twice weekly Discussion/work sessions Do your homework; I will call on you. Assignments &amp; evaluation Class attendance Exercises Final project Are we (scientists, the public) fooling ourselves? How can we know? Why might it matter? A humorous perspective (NYU Health Sciences Library 2013) Feynmann on ‘Cargo Cult Science’ Richard Feynman Figure 1.8: Richard P. Feynman, Wikipedia Who was he? Figure 1.9: (Feynman 1974) What does Feynman mean by ‘Cargo Cult Science’? I think the educational and psychological studies I mentioned are examples of what I would like to call Cargo Cult Science. In the South Seas there is a Cargo Cult of people. During the war they saw airplanes land with lots of good materials, and they want the same thing to happen now. So they’ve arranged to make things like runways, to put fires along the sides of the runways, to make a wooden hut for a man to sit in, with two wooden pieces on his head like headphones and bars of bamboo sticking out like antennas—he’s the controller—and they wait for the airplanes to land. They’re doing everything right. The form is perfect. It looks exactly the way it looked before. But it doesn’t work. No airplanes land. So I call these things Cargo Cult Science, because they follow all the apparent precepts and forms of scientific investigation, but they’re missing something essential, because the planes don’t land. More about “cargo cults”: (rjlipton 2023) Implicit rules (practices or norms) in science …That is the idea that we all hope you have learned in studying science in school—we never explicitly say what this is, but just hope that you catch on by all the examples of scientific investigation. It is interesting, therefore, to bring it out now and speak of it explicitly. It’s a kind of scientific integrity, a principle of scientific thought that corresponds to a kind of utter honesty—a kind of leaning over backwards. For example, if you’re doing an experiment, you should report everything that you think might make it invalid—not only what you think is right about it: other causes that could possibly explain your results; and things you thought of that you’ve eliminated by some other experiment, and how they worked—to make sure the other fellow can tell they have been eliminated. Principle 1: Don’t fool yourself The first principle is that you must not fool yourself—and you are the easiest person to fool. So you have to be very careful about that. After you’ve not fooled yourself, it’s easy not to fool other scientists. You just have to be honest in a conventional way after that. Principle 2: Show how your maybe wrong I’m talking about a specific, extra type of integrity that is not lying, but bending over backwards to show how you’re maybe wrong, that you ought to do when acting as a scientist. And this is our responsibility as scientists, certainly to other scientists, and I think to laymen. Principle 3: Publish your results whichever way they come out One example of the principle is this: If you’ve made up your mind to test a theory, or you want to explain some idea, you should always decide to publish it whichever way it comes out. If we only publish results of a certain kind, we can make the argument look good. We must publish both kinds of result. Figure 1.10: (Oreskes 2019) Flaws in how science is actually practiced Other kinds of errors are more characteristic of poor science. When I was at Cornell. I often talked to the people in the psychology department. One of the students told me she wanted to do an experiment that went something like this—I don’t remember it in detail, but it had been found by others that under certain circumstances, X, rats did something, A. She was curious as to whether, if she changed the circumstances to Y, they would still do, A. So her proposal was to do the experiment under circumstances Y and see if they still did A. I explained to her that it was necessary first to repeat in her laboratory the experiment of the other person—to do it under condition X to see if she could also get result A—and then change to Y and see if A changed. Then she would know that the real difference was the thing she thought she had under control. She was very delighted with this new idea, and went to her professor. And his reply was, no, you cannot do that, because the experiment has already been done and you would be wasting time. This was in about 1935 or so, and it seems to have been the general policy then to not try to repeat psychological experiments, but only to change the conditions and see what happens. Principle 4: Replicate then extend. Principle 5: Scientific integrity requires a form of freedom …So I have just one wish for you—the good luck to be somewhere where you are free to maintain the kind of integrity I have described, and where you do not feel forced by a need to maintain your position in the organization, or financial support, or so on, to lose your integrity. May you have that freedom. Questions to ponder Do you agree or disagree with Feynman’s characterizations of poor science? Why or why not? What are Feynman’s ‘rules’ or principles? Are these ‘rules’ or principles taught explicitly? Where and how? If not, why not? Do you agree or disagree that these rules are essential for scientific integrity? Why does Feynman suggest that you, the scientist or student, are the easiest one to fool? Going deeper Thu Jan 12: How science works or should work Tue Jan 17: Scientific norms and counter-norms Thu Jan 19: Adherence to norms and counter-norms. Exercise 01: Norms and counter-norms Begley’s ‘Bombshell’ Reading: (Harris 2017), Chapter 1. Figure 1.11: (Harris 2017) Background C. Glenn Begley (Begley and Ellis 2012) The scientific community assumes that the claims in a preclinical study can be taken at face value — that although there might be some errors in detail, the main message of the paper can be relied on and the data will, for the most part, stand the test of time. Unfortunately, this is not always the case. Over the past decade, before pursuing a particular line of research, scientists (including C.G.B.) in the haematology and oncology department at the biotechnology firm Amgen in Thousand Oaks, California, tried to confirm published findings related to that work. Fifty-three papers were deemed ‘landmark’ studies (see ‘Reproducibility of research findings’). It was acknowledged from the outset that some of the data might not hold up, because papers were deliberately selected that described something completely new, such as fresh approaches to targeting cancers or alternative clinical uses for existing therapeutics. Nevertheless, scientific findings were confirmed in only 6 (11%) cases. Even knowing the limitations of preclinical research, this was a shocking result. Journal Impact Factor \\(n\\) articles Mean number of citations for non-reproduced articles Mean number of citations of reproduced articles &gt;20 21 248 [3, 800] 231 [82-519] 5-19 32 168 [6, 1,909] 13 [3, 24] Table 1 from (Begley and Ellis 2012) Findings Findings of 6/53 published papers (11%) could be reproduced Original authors often could not reproduce their own work Earlier paper (Prinz, Schlange, and Asadullah 2011) had also found low rate of reproducibility. Paper titled “Believe it or not: How much can we rely on published data on potential drug targets?” Figure 1 from (Prinz, Schlange, and Asadullah 2011) We received input from 23 scientists (heads of laboratories) and collected data from 67 projects, most of them (47) from the field of oncology. This analysis revealed that only in ∼20–25% of the projects were the relevant published data completely in line with our in-house findings (Prinz, Schlange, and Asadullah 2011) Published papers (that can’t be reproduced) are cited hundreds or thousands of times Cost of irreproducible research estimated in billions of dollars (Freedman, Cockburn, and Simcoe 2015). An analysis of past studies indicates that the cumulative (total) prevalence of irreproducible preclinical research exceeds 50%, resulting in approximately US$28,000,000,000 (US$28B)/year spent on preclinical research that is not reproducible—in the United States alone. (Freedman, Cockburn, and Simcoe 2015). Figure 2 from (Freedman, Cockburn, and Simcoe 2015): Questions to ponder Why does Harris call this a ‘bombshell’? Do you agree that it has/had or should have an ‘explosive’ impact? Why? Why do Begley &amp; Ellis focus on a journal’s impact factor? Why do Begley &amp; Ellis focus on citations to reproduced vs. non-reproduced articles? Why should non-scientists care? Why should scientists in other fields (not cancer biology) care? Going deeper Tues Jan 24: Replication crisis Thu Feb 2: Replication in cancer biology Tue Feb 7: Reproducibility and replicability reconsidered. Exercise 04: Replication Learn more Talk by Begley (CrossFit 2019) Watching the talk by Begley is not required. But you might get inspired and decide to focus your final project around the topic. “What I’m alleging is that the reviewers, the editors of the so-called top-tier journals, grant review committees, promotion committees, and the scientific community repeatedly tolerate poor-quality science.” – C. Glenn Begley Next time… How science works (or should) Read (Ritchie 2020), Chapter 1. (Nosek and Bar-Anan 2012) Optional (Sagan 1996), Chapter 12, “The Fine Art of Baloney Detection” References "],["how-science-works-or-should.html", "How science works (or should) Prelude Announcement Roadmap Newsflash Last time Today’s topics Discuss (Ritchie 2020), Chapter 1 Discuss (Nosek and Bar-Anan 2012) Common themes Learn more Next time…", " How science works (or should) Prelude Announcement Penn State School of Theatre Free tickets Figure 1.12: https://theatre.psu.edu/centrestage Roadmap Newsflash Last time How science works (or should) Readings (Ritchie 2020), Chapter 1. (Nosek and Bar-Anan 2012) Optional (Sagan 1996), Chapter 12, “The Fine Art of Baloney Detection” Newsflash Hi Rick, Join us tomorrow at noon ET for a live presentation by the data science leaders at Roche about why they’re making open source the default for clinical trials in 2023. The presentation will take place on YouTube Live. You can tune in using this link. You can also add the event to your calendar as a reminder here. We couldn’t be more excited to highlight this historic industry shift. Thomas Neitmann, Ning Leng, and Dr. Kieran Martin will detail the years of preparation and innovation that went into making this shift a reality, along with how the organization plans to enable the transition of over 1,000 statistical programmers and statisticians to R and Python-centric tools. In the interest of providing additional context and drumming up some more excitement for the event, we highly recommend reading James Black’s ( Director of Insights Engineering at Roche) recent post on LinkedIn. We reserved time at the end of the presentation for questions, so don’t hesitate to show up curious! Additionally, if you have any questions that you’d like us to pass along to the team at Roche, feel free to respond directly to this email! From everyone at Posit and the incredible teams at Roche, we can’t wait to see you there! Robert @ RStudio Last time Comments on Feynman Comments on Begley &amp; Ellis Other comments or questions Extra credit opportunity Read (Feynman 1974) or one of (Harris 2017), Chapter 1, Begley’s Bombshell. PDF on Canvas or (Begley and Ellis 2012). In no more than one page, answer one of the questions posed in the notes from last time on Feynman or on Begley &amp; Ellis. Submit your answer via Canvas to Garrett by Monday, January 16, 2023 at 5:00 pm. Worth 2 points. Today’s topics How science works (or should) Discuss (Ritchie 2020), Chapter 1 Discuss (Nosek and Bar-Anan 2012) Discuss (Ritchie 2020), Chapter 1 Author Stuart J. Ritchie Scottish psychologist, Lecturer at King’s College London Figure 1.13: Stuart J. Ritchie Chapter 1: How Science Works “Science is a social construct.” How so? What are the consequences? What is the “process” of science? Figure 1.14: Figure 1 from (Munafò et al. 2017) Publish results But submit for peer review prior to publication Governed by “norms” Science’s social nature does come with weaknesses, however. Because scientists focus so much on trying to persuade their peers, which is the way they get those studies through peer review and oward to publication, it’s all too easy for them to disregard the real object of science: getting us closer to the truth. (Ritchie 2020), Chapter 1, pp. 14-15. Discuss (Nosek and Bar-Anan 2012) Authors Brian Nosek Social Psychologist, Professor at University of Virginia Co-Founder, Center for Open Science (COS) Founder, Project Implicit Figure 1.15: Brian Nosek Yoav Bar-Anon Social Psychology, Professor at Tel Aviv University Scientific Utopia: I. Opening Scientific Communication What’s Utopia Where’s Part II? Nosek, B. A., Spies, J. R. &amp; Motyl, M. (2012). Scientific utopia II: Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science: A Journal of the Association for Psychological Science, 7(6), 615–631. https://doi.org/10.1177/1745691612459058 Aims &amp; Claims Existing norms for scientific communication are rooted in anachronistic practices of bygone eras making them needlessly inefficient. We outline a path that moves away from the existing model of scientific communication to improve the efficiency in meeting the purpose of public science—knowledge accumulation. We call for six changes: (a) full embrace of digital communication; (b) open access to all published research; (c) disentangling publication from evaluation; (d) breaking the “one article, one journal” model with a grading system for evaluation and diversified dissemination outlets; (e) publishing peer review; and (f) allowing open, continuous peer review. We address conceptual and practical barriers to change and provide examples showing how the suggested practices are being used already. The critical barriers to change are not technical or financial; they are social. Although scientists guard the status quo, they also have the power to change it. Common themes Goals and purposes of science Utopian, idealistic aims Efficiency in achieving those goals High quality versus low quality science Ethics, scientific integrity Means of scientific communication Who has access, who should How are findings, articles, individuals evaluated Learn more Talk by Brian Nosek, (University of California Television (UCTV) 2018) Watching the talk by Nosek is not required. But he’s a very good speaker and an inspiring person. Next time… Scientific norms and counter-norms Read (Merton 1973). (Mitroff 1974). Assignment Complete (anonymous) survey on scientific norms and counter-norms. No write-up. References "],["scientific-norms-and-counter-norms.html", "Scientific norms and counter-norms Readings Assignment", " Scientific norms and counter-norms Readings Merton, R.K. (1973). The normative structure of science. In The Sociology of Science: Theoretical and Empirical Investigations. (Mitroff 1974). Assignment Complete (anonymous) survey on scientific norms and counter-norms. References "],["adherence-to-norms-and-counter-norms.html", "Adherence to norms and counter-norms Read", " Adherence to norms and counter-norms Read (Kardash and Edwards 2012). (Macfarlane and Cheng 2008). Skim (Anderson et al. 2010). (Kim and Kim 2018). References "],["a-replication-crisisor-not.html", "A replication crisis…or not Last time Today’s topics Next time", " A replication crisis…or not Last time Today’s topics A replication crisis…or not Read {-} (Ritchie 2020), Chapter 2. (Begley and Ellis 2012) (Optional) (Oreskes 2019), Chapter 7, pp. 228-244. Next time References "],["a-replication-failure-the-lady-macbeth-effect.html", "A replication failure: The “Lady Macbeth Effect” Last time Today’s topics", " A replication failure: The “Lady Macbeth Effect” Last time Today’s topics A replication failure: The “Lady Macbeth Effect” {-} Read {-} (Zhong and Liljenquist 2006) (Earp et al. 2014) Due Exercise 01: Norms and counter-norms write-up References "],["bias.html", "Topic 2 Bias 2.1 Read 2.2 Exercise 2.3 Kinds of bias 2.4 Discuss p-hacking exercise", " Topic 2 Bias 2.1 Read (Ritchie 2020), Chapter 4 2.2 Exercise P-hack your way to scientific glory 2.3 Kinds of bias 2.4 Discuss p-hacking exercise Who got a “significant” result? How many different analyses did you try? Who changed their analysis after finding a significant result? Did anyone try another analysis and keep the non-significant result? References "],["survey-1-results.html", "Survey 1 results Purpose Background Set-up Download data Clean data Visualize data", " Survey 1 results Purpose This document summarizes the analysis of data for Survey 1 on scientific norms and counter-norms (https://forms.gle/1zqzfNNXWyCgiDSJ9). Background The survey questions were derived from the Appendix in (Kardash and Edwards 2012). We thank these authors for publishing the survey questions in their article so that we could reuse them for our class. Set-up We load the required R packages. Download data Download the data file from the spreadsheet generated by the Google Form into a comma-separated value (CSV) file in a local directory called csv/. Authenticate to Google. Clean data Load the data file. Examine the variable names. These variable names are too long to be useful. Let’s look at the source publication (Kardash and Edwards 2012) to see if we can simplify them in a useful way. So, the Appendix labels each question with a short phrase and notes whether the concept is a norm (N) or counter-norm (CN). Let’s rename the variables using the single words. These data are ‘wide’, meaning that there are multiple variables for each respondent. The data will be easier to visualize and analyze if we make the data ‘longer’. Finally, there is a “test” set of responses that I used to test this data processing workflow. We should delete those responses since they are nonsensical–I just hit random buttons to make some data. Visualize data References "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
