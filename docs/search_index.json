[["index.html", "PSYCH 490.002 Spring 2023 notes About", " PSYCH 490.002 Spring 2023 notes Rick O. Gilmore, Ph.D. 2023-01-25 About These lecture notes are for your use as a student in PSYCH 490.002. "],["course-intro.html", "Course intro Prelude Today’s Topics Introductions Course overview Resources Themes/topics Structure Assignments &amp; evaluation Are we (scientists, the public) fooling ourselves? How can we know? Why might it matter? Learn more Next time…", " Course intro Prelude I like to have a series of songs or videos ready to play before class begins. They are loosely related to some of the themes of the course that day. Most are songs or artists I like. Showing them is just for fun. Today’s Topics Introductions Course overview Are we (scientists, the public) fooling ourselves? How can we know? Why might it matter? Introductions Teaching Assistant Garrett Thomas. M.S. gat84 AT-SIGN psu PERIOD edu Professor Rick O. Gilmore, Ph.D. Professor of Psychology Figure 1: https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/DenverCP.JPG/266px-DenverCP.JPG Figure 2: http://watson.brown.edu/ds/sites/all/themes/ds/img/header/brown_large.png Figure 3: https://www.wheretraveler.com/sites/default/files/styles/wt17_promoted/public/WashingtonDC-shutterstock_93633676.jpg?itok=IT7CL9PU Figure 4: https://ai.cs.cmu.edu/sites/default/files/CMU.png Figure 5: http://onwardstate.com/wp-content/uploads/2014/10/93 Figure 6: https://imaging.psu.edu Figure 7: https://nyu.databrary.org/web/images/logo/databrary-nav.svg Course overview Resources Themes/topics Structure Assignments/evaluation Resources Websites Syllabus: https://psu-psychology.github.io/psych-490-reproducibility-2023-spring/ Class notes: https://psu-psychology.github.io/psych-490-reproducibility-2023-spring-notes/ Book Other readings Book selections Scanned PDFs of book selections are available on Canvas: https://psu.instructure.com/courses/2245007/files/folder/readings Articles Retrieve them yourself via the URL (uniform resource locator) and the DOI (digital object identifier). Why do I do this? Themes/topics What is science trying to do? What practices and norms constitute better science? What practices and norms constitute poorer science? Is there a crisis of reproducibility or replicability in psychological science? Is there a crisis in other areas of science? What are scientists doing to address these criticisms? Structure Meet twice weekly Discussion/work sessions Do your homework; I will call on you. Assignments &amp; evaluation Class attendance Exercises Final project Are we (scientists, the public) fooling ourselves? How can we know? Why might it matter? A humorous perspective (NYU Health Sciences Library 2013) Feynmann on ‘Cargo Cult Science’ Richard Feynman Figure 8: Richard P. Feynman, Wikipedia Who was he? Figure 9: (Feynman 1974) What does Feynman mean by ‘Cargo Cult Science’? I think the educational and psychological studies I mentioned are examples of what I would like to call Cargo Cult Science. In the South Seas there is a Cargo Cult of people. During the war they saw airplanes land with lots of good materials, and they want the same thing to happen now. So they’ve arranged to make things like runways, to put fires along the sides of the runways, to make a wooden hut for a man to sit in, with two wooden pieces on his head like headphones and bars of bamboo sticking out like antennas—he’s the controller—and they wait for the airplanes to land. They’re doing everything right. The form is perfect. It looks exactly the way it looked before. But it doesn’t work. No airplanes land. So I call these things Cargo Cult Science, because they follow all the apparent precepts and forms of scientific investigation, but they’re missing something essential, because the planes don’t land. More about “cargo cults”: (rjlipton 2023) Implicit rules (practices or norms) in science …That is the idea that we all hope you have learned in studying science in school—we never explicitly say what this is, but just hope that you catch on by all the examples of scientific investigation. It is interesting, therefore, to bring it out now and speak of it explicitly. It’s a kind of scientific integrity, a principle of scientific thought that corresponds to a kind of utter honesty—a kind of leaning over backwards. For example, if you’re doing an experiment, you should report everything that you think might make it invalid—not only what you think is right about it: other causes that could possibly explain your results; and things you thought of that you’ve eliminated by some other experiment, and how they worked—to make sure the other fellow can tell they have been eliminated. Principle 1: Don’t fool yourself The first principle is that you must not fool yourself—and you are the easiest person to fool. So you have to be very careful about that. After you’ve not fooled yourself, it’s easy not to fool other scientists. You just have to be honest in a conventional way after that. Principle 2: Show how your maybe wrong I’m talking about a specific, extra type of integrity that is not lying, but bending over backwards to show how you’re maybe wrong, that you ought to do when acting as a scientist. And this is our responsibility as scientists, certainly to other scientists, and I think to laymen. Principle 3: Publish your results whichever way they come out One example of the principle is this: If you’ve made up your mind to test a theory, or you want to explain some idea, you should always decide to publish it whichever way it comes out. If we only publish results of a certain kind, we can make the argument look good. We must publish both kinds of result. Figure 10: (Oreskes 2019) Flaws in how science is actually practiced Other kinds of errors are more characteristic of poor science. When I was at Cornell. I often talked to the people in the psychology department. One of the students told me she wanted to do an experiment that went something like this—I don’t remember it in detail, but it had been found by others that under certain circumstances, X, rats did something, A. She was curious as to whether, if she changed the circumstances to Y, they would still do, A. So her proposal was to do the experiment under circumstances Y and see if they still did A. I explained to her that it was necessary first to repeat in her laboratory the experiment of the other person—to do it under condition X to see if she could also get result A—and then change to Y and see if A changed. Then she would know that the real difference was the thing she thought she had under control. She was very delighted with this new idea, and went to her professor. And his reply was, no, you cannot do that, because the experiment has already been done and you would be wasting time. This was in about 1935 or so, and it seems to have been the general policy then to not try to repeat psychological experiments, but only to change the conditions and see what happens. Principle 4: Replicate then extend. Principle 5: Scientific integrity requires a form of freedom …So I have just one wish for you—the good luck to be somewhere where you are free to maintain the kind of integrity I have described, and where you do not feel forced by a need to maintain your position in the organization, or financial support, or so on, to lose your integrity. May you have that freedom. Questions to ponder Do you agree or disagree with Feynman’s characterizations of poor science? Why or why not? What are Feynman’s ‘rules’ or principles? Are these ‘rules’ or principles taught explicitly? Where and how? If not, why not? Do you agree or disagree that these rules are essential for scientific integrity? Why does Feynman suggest that you, the scientist or student, are the easiest one to fool? Going deeper Thu Jan 12: How science works or should work Tue Jan 17: Scientific norms and counter-norms Thu Jan 19: Adherence to norms and counter-norms. Exercise 01: Norms and counter-norms Begley’s ‘Bombshell’ Reading: (Harris 2017), Chapter 1. Figure 11: (Harris 2017) Background C. Glenn Begley (Begley and Ellis 2012) The scientific community assumes that the claims in a preclinical study can be taken at face value — that although there might be some errors in detail, the main message of the paper can be relied on and the data will, for the most part, stand the test of time. Unfortunately, this is not always the case. Over the past decade, before pursuing a particular line of research, scientists (including C.G.B.) in the haematology and oncology department at the biotechnology firm Amgen in Thousand Oaks, California, tried to confirm published findings related to that work. Fifty-three papers were deemed ‘landmark’ studies (see ‘Reproducibility of research findings’). It was acknowledged from the outset that some of the data might not hold up, because papers were deliberately selected that described something completely new, such as fresh approaches to targeting cancers or alternative clinical uses for existing therapeutics. Nevertheless, scientific findings were confirmed in only 6 (11%) cases. Even knowing the limitations of preclinical research, this was a shocking result. Journal Impact Factor \\(n\\) articles Mean number of citations for non-reproduced articles Mean number of citations of reproduced articles &gt;20 21 248 [3, 800] 231 [82-519] 5-19 32 168 [6, 1,909] 13 [3, 24] Table 1 from (Begley and Ellis 2012) Findings Findings of 6/53 published papers (11%) could be reproduced Original authors often could not reproduce their own work Earlier paper (Prinz, Schlange, and Asadullah 2011) had also found low rate of reproducibility. Paper titled “Believe it or not: How much can we rely on published data on potential drug targets?” Figure 1 from (Prinz, Schlange, and Asadullah 2011) We received input from 23 scientists (heads of laboratories) and collected data from 67 projects, most of them (47) from the field of oncology. This analysis revealed that only in ∼20–25% of the projects were the relevant published data completely in line with our in-house findings (Prinz, Schlange, and Asadullah 2011) Published papers (that can’t be reproduced) are cited hundreds or thousands of times Cost of irreproducible research estimated in billions of dollars (Freedman, Cockburn, and Simcoe 2015). An analysis of past studies indicates that the cumulative (total) prevalence of irreproducible preclinical research exceeds 50%, resulting in approximately US$28,000,000,000 (US$28B)/year spent on preclinical research that is not reproducible—in the United States alone. (Freedman, Cockburn, and Simcoe 2015). Figure 2 from (Freedman, Cockburn, and Simcoe 2015) Information about U.S. Research &amp; Development (R&amp;D) Expenditures from the Congressional Research Service. - Note that business accounts for 2-3x+ the Government’s share of R&amp;D expenditures. Questions to ponder Why does Harris call this a ‘bombshell’? Do you agree that it has/had or should have an ‘explosive’ impact? Why? Why do Begley &amp; Ellis focus on a journal’s impact factor? Why do Begley &amp; Ellis focus on citations to reproduced vs. non-reproduced articles? Why should non-scientists care? Why should scientists in other fields (not cancer biology) care? Going deeper Tues Jan 24: Replication crisis Thu Feb 2: Replication in cancer biology Tue Feb 7: Reproducibility and replicability reconsidered. Exercise 04: Replication Learn more Talk by Begley (CrossFit 2019) Watching the talk by Begley is not required. But you might get inspired and decide to focus your final project around the topic. “What I’m alleging is that the reviewers, the editors of the so-called top-tier journals, grant review committees, promotion committees, and the scientific community repeatedly tolerate poor-quality science.” – C. Glenn Begley Next time… How science works (or should) Read (Ritchie 2020), Chapter 1. (Nosek and Bar-Anan 2012) Optional (Sagan 1996), Chapter 12, “The Fine Art of Baloney Detection” References "],["how-science-works-or-should.html", "How science works (or should) Prelude Announcement Roadmap Newsflash Last time Today’s topics Discuss (Ritchie 2020), Chapter 1 Discuss (Nosek and Bar-Anan 2012) Common themes Learn more Next time…", " How science works (or should) Prelude Announcement Penn State School of Theatre Free tickets Figure 12: https://theatre.psu.edu/centrestage Roadmap Newsflash Last time How science works (or should) Readings (Ritchie 2020), Chapter 1. (Nosek and Bar-Anan 2012) Optional (Sagan 1996), Chapter 12, “The Fine Art of Baloney Detection” Newsflash Hi Rick, Join us tomorrow at noon ET for a live presentation by the data science leaders at Roche about why they’re making open source the default for clinical trials in 2023. The presentation will take place on YouTube Live. You can tune in using this link. You can also add the event to your calendar as a reminder here. We couldn’t be more excited to highlight this historic industry shift. Thomas Neitmann, Ning Leng, and Dr. Kieran Martin will detail the years of preparation and innovation that went into making this shift a reality, along with how the organization plans to enable the transition of over 1,000 statistical programmers and statisticians to R and Python-centric tools. In the interest of providing additional context and drumming up some more excitement for the event, we highly recommend reading James Black’s ( Director of Insights Engineering at Roche) recent post on LinkedIn. We reserved time at the end of the presentation for questions, so don’t hesitate to show up curious! Additionally, if you have any questions that you’d like us to pass along to the team at Roche, feel free to respond directly to this email! From everyone at Posit and the incredible teams at Roche, we can’t wait to see you there! Robert @ RStudio Last time Comments on Feynman Comments on Begley &amp; Ellis Other comments or questions Extra credit opportunity Read (Feynman 1974) or one of (Harris 2017), Chapter 1, Begley’s Bombshell. PDF on Canvas or (Begley and Ellis 2012). In no more than one page, answer one of the questions posed in the notes from last time on Feynman or on Begley &amp; Ellis. Submit your answer via Canvas to Garrett by Monday, January 16, 2023 at 5:00 pm. Worth 2 points. Today’s topics How science works (or should) Discuss (Ritchie 2020), Chapter 1 Discuss (Nosek and Bar-Anan 2012) Discuss (Ritchie 2020), Chapter 1 Author Stuart J. Ritchie Scottish psychologist, Lecturer at King’s College London Figure 13: Stuart J. Ritchie Chapter 1: How Science Works “Science is a social construct.” How so? What are the consequences? What is the “process” of science? Figure 14: Figure 1 from (Munafò et al. 2017) Publish results But submit for peer review prior to publication Governed by “norms” Science’s social nature does come with weaknesses, however. Because scientists focus so much on trying to persuade their peers, which is the way they get those studies through peer review and oward to publication, it’s all too easy for them to disregard the real object of science: getting us closer to the truth. (Ritchie 2020), Chapter 1, pp. 14-15. Discuss (Nosek and Bar-Anan 2012) Authors Brian Nosek Social Psychologist, Professor at University of Virginia Co-Founder, Center for Open Science (COS) Founder, Project Implicit Figure 15: Brian Nosek Yoav Bar-Anon Social Psychology, Professor at Tel Aviv University Scientific Utopia: I. Opening Scientific Communication What’s Utopia Where’s Part II? Nosek, B. A., Spies, J. R. &amp; Motyl, M. (2012). Scientific utopia II: Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science: A Journal of the Association for Psychological Science, 7(6), 615–631. https://doi.org/10.1177/1745691612459058 Aims &amp; Claims Existing norms for scientific communication are rooted in anachronistic practices of bygone eras making them needlessly inefficient. We outline a path that moves away from the existing model of scientific communication to improve the efficiency in meeting the purpose of public science—knowledge accumulation. We call for six changes: (a) full embrace of digital communication; (b) open access to all published research; (c) disentangling publication from evaluation; (d) breaking the “one article, one journal” model with a grading system for evaluation and diversified dissemination outlets; (e) publishing peer review; and (f) allowing open, continuous peer review. We address conceptual and practical barriers to change and provide examples showing how the suggested practices are being used already. The critical barriers to change are not technical or financial; they are social. Although scientists guard the status quo, they also have the power to change it. Common themes Goals and purposes of science Utopian, idealistic aims Efficiency in achieving those goals High quality versus low quality science Ethics, scientific integrity Means of scientific communication Who has access, who should How are findings, articles, individuals evaluated Learn more Talk by Brian Nosek, (University of California Television (UCTV) 2018) Watching the talk by Nosek is not required. But he’s a very good speaker and an inspiring person. Next time… Scientific norms and counter-norms Read (Merton 1973). (Mitroff 1974). Assignment Complete (anonymous) survey on scientific norms and counter-norms. No write-up. References "],["scientific-norms-and-counter-norms.html", "Scientific norms and counter-norms Roadmap Discuss (Merton 1973) Discuss (Mitroff 1974) Next time…", " Scientific norms and counter-norms Roadmap Last time How science works (or should) Readings (Merton 1973). PDF on Canvas. (Mitroff 1974). PDF on Canvas. Assignment Complete (anonymous) survey on scientific norms and counter-norms. Extra credit opportunity Read (Feynman 1974) or one of (Harris 2017), Chapter 1, Begley’s Bombshell. PDF on Canvas or (Begley and Ellis 2012). In no more than one page, answer one of the questions posed in the notes from last time on Feynman or on Begley &amp; Ellis. Submit your answer via Canvas to Garrett by Monday, January 16, 2023 at 5:00 pm. Worth 2 points. Discuss (Merton 1973) Figure 16: Robert K. Merton: Wikipedia Note: Merton 1973 PDF on Canvas Difficult as the notion may appear to those reared in a culture that grants science a prominent if not a commanding place in the scheme of things, it is evident that science is not immune from attack, restraint, and repression. Writing a little while ago, Veblen could observe that the faith of western culture in science was unbounded, unquestioned, unrivaled. The revolt from science which then appeared so improbable as to concern only the timid academician who would ponder all contingencies, however remote, has now been forced upon the attention of scientist and layman alike. Local contagions of anti-intellectualism threaten to become epidemic. – (Merton 1973), p. 267 Science is a deceptively inclusive word which refers to a variety of distinct though interrelated items. It is commonly used to denote (1) a set of characteristic methods by means of which knowledge is certified; (2) a stock of accumulated knowledge stemming from the application of these methods; (3) a set of cultural values and mores governing the activities termed scientific; or (4) any combination of the foregoing. – (Merton 1973), p. 268 The ethos of science The mores of science possess a methodologic rationale but they are binding, not only because they are procedurally efficient, but because they are believed right and good. – (Merton 1973), p. 270 Universalism See paragraph at top of p. 271 for context about the following: Yet this very deviation from the norm of universalism actually presupposed the the legitimacy of the norm. For nationalistic bias is oppropbrious only if judged in terms of the standard of universalism; within another institutional context, it is redefined as a virtue patriotism. Thus, in the process of condemning their violation, the mores are reaffirmed. – (Merton 1973), p. 271 To restrict scientific careers on grounds other than lack of competence is to prejudice the furtherance of knowledge. – (Merton 1973), p. 272 “Communism” Often called “communalism” today “Communism” in the nontechnical and extended sense of common ownership of goods…The substantive findings of science are a product of a social collaboration and are assigned to the community…Property rights in sciences are whittled down to a bare minimum by the rationale of the scientific ethic. – (Merton 1973), p. 273 The institutional conception of science as part of the public domain is linked with the imperative for communication of scientific findings. Secrecy is the antithesis of this norm; full and open communication is its enactment. – (Merton 1973), p. 274 Henry Cavendish was known for not publishing much of his work. Disinterestedness disinterested The virtual absence of fraud in the annals of science, which appears exceptional when compared with the record of other spheres of activity, has at times been attributed to the personal qualities of scientists…There is, in fact, no satisfactory evidence that such is the case; a more plausible explanation may be found in certain characteristcs of science itself…the activities of scientists are subject to rigorous policing, to a degree perhaps unparalleled in any other field of activity. – (Merton 1973), p. 276 It is probable that the reputability of science and its lofty ethical status in the estimate of the layman is in no small measure due to technological achievements…the laity is often in no position to distinguish spurious from genuine claims…The presumably scientific pronouncements of totalitarian spokensmen are for the uninstructed laity of the same order as newspaper reports on an expanding universe or wave mechanics. – (Merton 1973), p. 277 Organized Skepticism …is variously interrelated with other elements of the scientific ethos. It is both a methodological and institutional mandate. – (Merton 1973), p. 277 The scientific investigator does not preserve the cleavage between the sacred and the profane, between that which requires uncritical respect and that which can be objectively analyzed. – (Merton 1973), p. 277-278 Mnemonic: C-U-D-OS Discuss (Mitroff 1974) Ian I. Mitroff Figure 17: Ian I. Mitroff: Fig source Amazon …the personal character of science infuses its entire structure. The testing and validating of scientific ideas is as governed by the deep personal character of science as the initial discovery of the ideas…Polyani (1958) argues that not only is this the case, but it ought to be the case. That is, science outght to be personal to its core. – (Mitroff 1974), p. 580 …what the body of scientists thought about their fellow scientists. Who were perceived as most committed to their pet hypotheses? What did they think of such behavior? What did the scientists think of the abstract idea of commitment [to a pet hypothesis] itself… – (Mitroff 1974), p. 582 All the interviews exhibit high affective content. They document the often fierce, sometimes bitter, competitive races for discovery and the intense emotions which permeate the doing of science. – (Mitroff 1974), p. 585 The term “commitment” was used in three distinct (but related) senses. The first expresssed the notion of intellectual commitment, that is that scientific observerations were theory-laden…The second sense expressed the notion of affective commitment…The third sense expressed the notion that the entire process of science demanded deep personal commitment. – (Mitroff 1974), p. 586 Table 4: A Tentative List of Norms and Counternorms Norms Counternorms 1. Faith in the moral virtue of rationality (Barber, 1952). 1. Faith in the moral virtue of rationality and nonrationality (cf., Tart, 1972). 2. Emotional neutrality as an instrumental condition for the achievement of rationality (Barber, 1952). 2. Emotional commitment as an instrumental condition for the achievement of rationality. 3. Universalism: “The acceptance or rejection of claims entering the list of science is not to depend on the personal or social attributes of their protagonist; his race, nationality, religion, class and personal qualities are as such irrelevant. Objectivity precludes particularism …. The imperative of universalism is rooted deep in the impersonal character of science” (Merton, 1949:607). 3. Particularism: “The acceptance or rejection of claims entering the list of science is to a large extent a function of who makes the claim” (Boguslaw, 1968:59). The social and psychological characteristics of the scientist are important factors influencing how his work will be judged. The work of certain scientists will be given priority over that of others (Mitroff, 1974b). The imperative of particularism is rooted deep in the personal character of science (Merton, 1963a; Polanyi, 1958). 4. Communism: “Property rights are reduced to the absolute minimum of credit for priority of discovery” (Barber, 1952:130). “Secrecy is the antithesis’ of this norm; full and open communication [of scientific results] its enactment” (Merton, 1949:611). 4. Solitariness (or, “Miserism” [Boguslaw, 1968:59]): Property rights are expanded to include protective control over the disposition of one’s discoveries; secrecy thus becomes a necessary moral act (Mitroff, 1974b). 5. Disinterestedness: “Scientists are expected by their peers to achieve the self-interest they have in work–satisfaction and in prestige through serving the [scientific] community interest directly” (Barber, 1952:132). 5. Interestedness: Scientists are expected by their close colleagues to achieve the self-interest they have in work-satisfaction and in prestige through serving their special communities of interest, e.g., their invisible college (Boguslaw, 1968:59; Mitroff, 1974b) 6. Organized scepticism: “The scientist is obliged … to make public his criticisms of the work of others when he believes it to be in error … no scientist’s contribution to knowledge can be accepted without careful scrutiny, and that the scientist must doubt his own findjngs as well as those of others” (Storer, 1966: 79). 6. Organized dogmatism: “Each scientist should make certain that previous work by others on which he bases his work is sufficiently identified so that others can be held responsible for inadequacies while any possible credit accrues to oneself” (Boguslaw, 1968:59). The scientist must believe in his own findings with utter conviction while doubting those of others with all his worth (Mitroff, 1974b). Adapted from Table 4. (Mitroff 1974), p. 592. Next time… Adherence to norms and counter-norms Read (Kardash and Edwards 2012). (Macfarlane and Cheng 2008). Skim (Anderson et al. 2010). (Kim and Kim 2018). Assignment Exercise 01: Norms and counter-norms write-up References "],["adherence-to-norms-and-counter-norms.html", "Adherence to norms and counter-norms Roadmap Discuss (Kardash and Edwards 2012) How do our results compare? Discuss (Macfarlane and Cheng 2008) Looking ahead…", " Adherence to norms and counter-norms Roadmap Last time Scientific norms and counter-norms Readings (Kardash and Edwards 2012). (Macfarlane and Cheng 2008). Skim (Anderson et al. 2010). (Kim and Kim 2018). Survey results Assignment Exercise 01: Norms and counter-norms write-up How to read a paper What type of paper is it? Empirical, theoretical, review, opinion, other? Read the abstract carefully for answers to the following questions: Who is the target audience? Why did the author(s) do this work? What question were they trying to answer or what view were they trying to argue for? What is the take-home message or main finding(s)? For empirical papers, Who were the participants? What were their characteristics? What was measured? When or how often were the measurements taken? Read the Methods section Look at the figures in the Results section Do the figures “tell the story” of the paper? Imagine how you would complete the following synthesis: “This paper asks X by measuring Y in Z. It found Q, which suggests R. The paper is flawed because of S.” Read the Introduction and/or the Discussion if you need or want to know more. Other tips Highlight/flag unfamiliar terms or acronyms, but don’t stop reading to look them up until later. Keep a reference manager program; grab papers and sift through them later. Discuss (Kardash and Edwards 2012) Kardash, C. M. &amp; Edwards, O. V. (2012). Thinking and behaving like scientists: Perceptions of undergraduate science interns and their faculty mentors. Instructional Science, 40(6), 875–899. https://doi.org/10.1007/s11251-011-9195-0 Figure 18: CarolAnne M. Kardash: Source https://www.dignitymemorial.com/obituaries/las-vegas-nv/carolanne-kardash-10908219 Abstract We examined undergraduate research experiences (UREs) participants’ and their faculty mentors’ beliefs about the professional practices and dispositions of research scientists. In Study 1, 63 science interns and their mentors rated Merton’s (J Legal Political Sociol, 1:115–126, 1942) norms and Mitroff’s (Am Sociol Rev, 39(August):579–595, 1974) counter-norms of scientific practice. Specifically, we investigated what practices they believed research scientists should subscribe to (or not), and what practices they believed actually characterized research scientists’ behavior in the real world. Regarding idealized practice, mentors rated the norms significantly higher than did interns; mentors and interns generally did not differ in subscription to the counter-norms. Regarding actual practice, mentors believed scientists’ behaviors reflected counter-norms more than norms. Mentors further noted discrepancies between practices that should represent and actually did represent scientists’ work. In Study 2, interns and mentors listed characteristics associated with “thinking” and “behaving” like scientists. Personal and professional dispositions were mentioned more than intellectual and research skills. Although there was considerable consensus between faculty and intern perceptions, findings also revealed discrepancies that could be addressed in UREs, thereby aiding undergraduates’ socialization into the culture of scientific practice. Suggestions are provided for broadening interns’ conceptions of both scientists and science. …uncovering science majors’ conceptions of one aspect of academic life in the sciences—namely, what it means to think and behave like a research scientist. Specifically, we compared science undergraduates’ and faculty mentors’ perceptions of the practices and personal characteristics of research scientists. – (Kardash and Edwards 2012) As students find themselves immersed in the day to day practices of researchers, what values, practices, and dispositions capture their attention, become most salient to them and provide the foundation for their beliefs about what constitutes the professional identity of research scientists? As important, to what extent are students’ perceptions of these values, practices, and dispositions congruent with the perceptions of the faculty mentors? – (Kardash and Edwards 2012) Constantinides (2001) provides the following descriptions of the norms (p. 63): Universalism requires that knowledge claims be subjected to pre-established, impersonal criteria. Communality dictates that research belongs to the community of scientists rather than the individual researcher. Disinterestedness prescribes disinterested scientific activity, which is enforced by the accountability of scientists to their peers. Organized skepticism requires that claims be critically scrutinized in terms of empirical and logical criteria. – (Kardash and Edwards 2012) Study 1 Figure 19: Figure 1 from (Kardash and Edwards 2012) Study 2 Link to Table 1 This study could be replicated in some form as a final project. How do our results compare? A student could extend this analysis or do additional analyses as a final project. Discuss (Macfarlane and Cheng 2008) Macfarlane, B. &amp; Cheng, M. (2008). Communism, universalism and disinterestedness: Re-examining contemporary support among academics for Merton’s scientific norms. Journal of Academic Ethics, 6(1), 67–78. https://doi.org/10.1007/s10805-008-9055-y Figure 20: Bruce Macfarlane: https://hk.linkedin.com/in/bruce-macfarlane-244582a1 Figure 21: Ming Cheng: https://scholar.google.com/citations?user=4o9OsswAAAAJ&amp;hl=en Abstract This paper re-examines the relevance of three academic norms to contemporary academic life – communism, universalism and disinterestedness – based on the work of Robert Merton. The results of a web-based survey elicited responses to a series of value statements and were analysed using the weighted average method and through cross-tabulation. Results indicate strong support for communism as an academic norm defined in relation to sharing research results and teaching materials as opposed to protecting intellectual copyright and withholding access. There is more limited support for universalism based on the belief that academic knowledge should transcend national, political, or religious boundaries. Disinterestedness, defined in terms of personal detachment from truth claims, is the least popular contemporary academic norm. Here, the impact of a performative culture is linked to the need for a large number of academics to align their research interests with funding opportunities. The paper concludes by considering the claims of an alternate set of contemporary academic norms including capitalism, particularism and interestedness. Figure 22: Fig 1: https://link.springer.com/article/10.1007/s10805-008-9055-y/figures/1 Figure 23: Fig 2: https://link.springer.com/article/10.1007/s10805-008-9055-y/figures/2 Figure 24: Fig 3: https://link.springer.com/article/10.1007/s10805-008-9055-y/figures/3 Figure 25: Fig 4: https://link.springer.com/article/10.1007/s10805-008-9055-y/figures/4 Figure 26: Fig 5: https://link.springer.com/article/10.1007/s10805-008-9055-y/figures/5 Figure 27: Fig 6: https://link.springer.com/article/10.1007/s10805-008-9055-y/figures/6 Figure 28: Fig 7: https://link.springer.com/article/10.1007/s10805-008-9055-y/figures/7 Figure 29: Fig 8: https://link.springer.com/article/10.1007/s10805-008-9055-y/figures/8 Conclusion The results of the survey do not necessarily represent a ‘shift’ in values as Merton’s norms were not based on empirical data. While this research sample was broadly representative of academic staff by gender, this does not necessarily imply that it is representative of the academic profession in all respects. However, contemporary performative pressures on academic life may be having an impact in shaping, or perhaps re-shaping, some Mertonian norms. This is particularly apparent in respect to the norm of disinterestedness where large numbers of academics pragmatically align their research interests with funding opportunities. This finding may be related to a more competitive market-based university environment apparent in the UK and elsewhere internationally where it has been argued that the canons of scientific inquiry have been compromised by commercial pressures (Bok 2003). Despite these pressures, the norm of communism, in particular, still attracts strong popular espoused support which crosses disciplinary fields. The balance of evidence from this survey, though, suggests that market-based and commercial pressures might be beginning to subvert the Mertonian ideal. However, respondents’ support of universalism and disinterestedness varies with their subjects. In general, respondents from applied sciences showed stronger support for these two norms than respondents from the other subject fields. – (Macfarlane and Cheng 2008) This paper would be slightly harder to reproduce as a final project, but something similar is possible. Looking ahead… Assignment Exercise 01: Norms and counter-norms write-up Due next Thursday, January 26. Replication crisis (or not) Read (Ritchie 2020), Chapter 2. (Begley and Ellis 2012) (Optional) (Oreskes 2019), Chapter 7, pp. 228-244. References "],["a-replication-crisis.html", "A replication crisis Roadmap Replication crisis…or not Reproducibility in psychological science Reproducibility in pre-clinical cancer biology Looking ahead", " A replication crisis Roadmap Announcements Assignment Exercise 01: Norms and counter-norms write-up Last time… Scientific norms and counter-norms Readings (Kardash and Edwards 2012). (Macfarlane and Cheng 2008). Skim (Anderson et al. 2010). (Kim and Kim 2018). Survey results Today’s topics A replication crisis…or not Read (Ritchie 2020), Chapter 2. PDF on Canvas. (Begley and Ellis 2012) (Optional) (Oreskes 2019), Chapter 7, pp. 228-244 Replication crisis…or not What proportion of findings in the published scientific literature (in the fields you care about) are actually true? 100% 90% 70% 50% 30% How do we define what “actually true” means? How widespread is the problem? Figure 30: (Baker 2016) Figure 31: (Baker 2016) Figure 32: (Baker 2016) These questions could form the basis of a final project where a student or students re-run the survey with a different sample. What do the terms mean? Replication refers to testing the reliability of a prior finding with different data. Robustness refers to testing the reliability of a prior finding using the same data and a different analysis strategy. Reproducibility refers to testing the reliability of a prior finding using the same data and the same analysis strategy (Natl. Acad. Sci. Eng. Med. 2019). Each of the three notions plays an important role in assessing credibility. – (Nosek et al. 2022) In principle, all reported evidence should be reproducible. If someone applies the same analysis to the same data, the same result should occur. Reproducibility tests can fail for two reasons. A process reproducibility failure occurs when the original analysis cannot be repeated because of the unavailability of data, code, information needed to recreate the code, or necessary software or tools. An outcome reproducibility failure occurs when the reanalysis obtains a different result than the one reported originally. This can occur because of an error in either the original or the reproduction study. – (Nosek et al. 2022) Different types of reproducibility? (Goodman, Fanelli, and Ioannidis 2016) Methods reproducibility Enough details about materials &amp; methods recorded (&amp; reported) Same results with same materials &amp; methods (Goodman, Fanelli, and Ioannidis 2016) Figure 33: If you got hit by a bus, could your colleagues replicate and build on your work? What’s your project’s ‘bus number’? Results reproducibility Same results from independent study (Goodman, Fanelli, and Ioannidis 2016) Inferential reproducibility Same inferences from one or more studies or reanalyses (Goodman, Fanelli, and Ioannidis 2016) Reproducibility in psychological science Replication failure: The “Lady Macbeth Effect” Read and discuss this Thursday, January 26, 2023 Replication failure: Priming effect Read and discuss next Tuesday, January 31, 2023 (Artner et al. 2021) We investigated the reproducibility of the major statistical conclusions drawn in 46 articles published in 2012 in three APA journals. After having identified 232 key statistical claims, we tried to reproduce, for each claim, the test statistic, its degrees of freedom, and the corresponding p value, starting from the raw data that were provided by the authors and closely following the Method section in the article. Out of the 232 claims, we were able to successfully reproduce 163 (70%), 18 of which only by deviating from the article’s analytical description. Thirteen (7%) of the 185 claims deemed significant by the authors are no longer so. The reproduction successes were often the result of cumbersome and time-consuming trial-and-error work, suggesting that APA style reporting in conjunction with raw data makes numerical verification at least hard, if not impossible. – (Artner et al. 2021) (Collaboration 2015) Open Science Collaboration. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716–aac4716. https://doi.org/10.1126/science.aac4716 Read and discuss on Tuesday, March 21, 2023 (Camerer et al. 2018) Camerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., Altmejd, A., Buttrick, N., Chan, T., Chen, Y., Forsell, E., Gampa, A., Heikensten, E., Hummer, L., Imai, T., … Wu, H. (2018). Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015. Nature Human Behaviour, 1. https://doi.org/10.1038/s41562-018-0399-z Read and discuss on Tuesday, March 21, 2023 (Whitt, Miranda, and Tullett 2022) Whitt, C. M., Miranda, J. F. &amp; Tullett, A. M. (2022). History of Replication Failures in Psychology. In W. O’Donohue, A. Masuda &amp; S. Lilienfeld (Eds.), Avoiding Questionable Research Practices in Applied Psychology (pp. 73–97). Springer International Publishing. https://doi.org/10.1007/978-3-031-04968-2_4 Is psychology harder than physics? Reproducibility in pre-clinical cancer biology Reading: (Begley and Ellis 2012) Discuss replication in cancer biology on Thursday, February 2, 2023. Background C. Glenn Begley (Begley and Ellis 2012) The scientific community assumes that the claims in a preclinical study can be taken at face value — that although there might be some errors in detail, the main message of the paper can be relied on and the data will, for the most part, stand the test of time. Unfortunately, this is not always the case. Over the past decade, before pursuing a particular line of research, scientists (including C.G.B.) in the haematology and oncology department at the biotechnology firm Amgen in Thousand Oaks, California, tried to confirm published findings related to that work. Fifty-three papers were deemed ‘landmark’ studies (see ‘Reproducibility of research findings’). It was acknowledged from the outset that some of the data might not hold up, because papers were deliberately selected that described something completely new, such as fresh approaches to targeting cancers or alternative clinical uses for existing therapeutics. Nevertheless, scientific findings were confirmed in only 6 (11%) cases. Even knowing the limitations of preclinical research, this was a shocking result. Journal Impact Factor \\(n\\) articles Mean number of citations for non-reproduced articles Mean number of citations of reproduced articles &gt;20 21 248 [3, 800] 231 [82-519] 5-19 32 168 [6, 1,909] 13 [3, 24] Table 1 from (Begley and Ellis 2012) Findings Findings of 6/53 published papers (11%) could be reproduced Original authors often could not reproduce their own work Earlier paper (Prinz, Schlange, and Asadullah 2011) had also found low rate of reproducibility. Paper titled “Believe it or not: How much can we rely on published data on potential drug targets?” Figure 1 from (Prinz, Schlange, and Asadullah 2011) We received input from 23 scientists (heads of laboratories) and collected data from 67 projects, most of them (47) from the field of oncology. This analysis revealed that only in ∼20–25% of the projects were the relevant published data completely in line with our in-house findings (Prinz, Schlange, and Asadullah 2011) Published papers (that can’t be reproduced) are cited hundreds or thousands of times Cost of irreproducible research estimated in billions of dollars (Freedman, Cockburn, and Simcoe 2015). An analysis of past studies indicates that the cumulative (total) prevalence of irreproducible preclinical research exceeds 50%, resulting in approximately US$28,000,000,000 (US$28B)/year spent on preclinical research that is not reproducible—in the United States alone. (Freedman, Cockburn, and Simcoe 2015). Figure 2 from (Freedman, Cockburn, and Simcoe 2015) Information about U.S. Research &amp; Development (R&amp;D) expenditures from the Congressional Research Service. Note that business accounts for 2-3x+ the Government’s share of R&amp;D expenditures. Questions to ponder Why do Begley &amp; Ellis focus on a journal’s impact factor? Why do Begley &amp; Ellis focus on citations to reproduced vs. non-reproduced articles? Why should non-scientists care? Why should scientists in other fields (not cancer biology) care? Learn more Talk by Begley (CrossFit 2019) “What I’m alleging is that the reviewers, the editors of the so-called top-tier journals, grant review committees, promotion committees, and the scientific community repeatedly tolerate poor-quality science.” – C. Glenn Begley Watching the talk by Begley is not required. But you might get inspired and decide to focus your final project around the topic. (Nosek et al. 2022) Nosek, B. A., Hardwicke, T. E., Moshontz, H., Allard, A., Corker, K. S., Dreber, A., Fidler, F., Hilgard, J., Kline Struhl, M., Nuijten, M. B., Rohrer, J. M., Romero, F., Scheel, A. M., Scherer, L. D., Schönbrodt, F. D. &amp; Vazire, S. (2022). Replicability, robustness, and reproducibility in psychological science. Annual Review of Psychology, 73(2022), 719–748. https://doi.org/10.1146/annurev-psych-020821-114157 Replication—an important, uncommon, and misunderstood practice—is gaining appreciation in psychology. Achieving replicability is important for making research progress. If findings are not replicable, then prediction and theory development are stifled. If findings are replicable, then interrogation of their meaning and validity can advance knowledge. Assessing replicability can be productive for generating and testing hypotheses by actively confronting current understandings to identify weaknesses and spur innovation. For psychology, the 2010s might be characterized as a decade of active confrontation. Systematic and multi-site replication projects assessed current understandings and observed surprising failures to replicate many published findings. Replication efforts highlighted sociocultural challenges such as disincentives to conduct replications and a tendency to frame replication as a personal attack rather than a healthy scientific practice, and they raised awareness that replication contributes to self-correction. Nevertheless, innovation in doing and understanding replication and its cousins, reproducibility and robustness, has positioned psychology to improve research practices and accelerate progress. (Peng and Hicks 2021) Peng, R. D. &amp; Hicks, S. C. (2021). Reproducible research: A retrospective. Annual Review of Public Health, 42, 79–93. https://doi.org/10.1146/annurev-publhealth-012420-105110 Advances in computing technology have spurred two extraordinary phenomena in science: large-scale and high-throughput data collection coupled with the creation and implementation of complex statistical algorithms for data analysis. These two phenomena have brought about tremendous advances in scientific discovery but have raised two serious concerns. The complexity of modern data analyses raises questions about the reproducibility of the analyses, meaning the ability of independent analysts to recreate the results claimed by the original authors using the original data and analysis techniques. Reproducibility is typically thwarted by a lack of availability of the original data and computer code. A more general concern is the replicability of scientific findings, which concerns the frequency with which scientific claims are confirmed by completely independent investigations. Although reproducibility and replicability are related, they focus on different aspects of scientific progress. In this review, we discuss the origins of reproducible research, characterize the current status of reproducibility in public health research, and connect reproducibility to current concerns about the replicability of scientific findings. Finally, we describe a path forward for improving both the reproducibility and replicability of public health research in the future. Reading and writing a commentary on either of these articles might be a good final project. Looking ahead A replication failure: The “Lady Macbeth Effect” Read (Zhong and Liljenquist 2006) (Earp et al. 2014) Due Exercise 01: Norms and counter-norms write-up References "],["a-replication-failure-the-lady-macbeth-effect.html", "A replication failure: The “Lady Macbeth Effect” Roadmap (Zhong and Liljenquist 2006) (Earp et al. 2014) Side-by-side comparisons", " A replication failure: The “Lady Macbeth Effect” Roadmap Announcements Assignment Exercise 01: Norms and counter-norms write-up due today Last time Today’s topic A replication failure: The “Lady Macbeth Effect” Read (Zhong and Liljenquist 2006) (Earp et al. 2014) (Zhong and Liljenquist 2006) Zhong, C.-B. &amp; Liljenquist, K. (2006). Washing away your sins: Threatened morality and physical cleansing. Science, 313(5792), 1451–1452. https://doi.org/10.1126/science.1130726 How to read a paper Type of paper: empirical|theoretical|review|opinion|other Physical cleansing has been a focal element in religious ceremonies for thousands of years. The prevalence of this practice suggests a psychological association between bodily purity and moral purity. In three studies, we explored what we call the “Macbeth effect”—that is, a threat to one’s moral purity induces the need to cleanse oneself. This effect revealed itself through an increased mental accessibility of cleansing-related concepts, a greater desire for cleansing products, and a greater likelihood of taking antiseptic wipes. Furthermore, we showed that physical cleansing alleviates the upsetting consequences of unethical behavior and reduces threats to one’s moral self-image. Daily hygiene routines such as washing hands, as simple and benign as they might seem, can deliver a powerful antidote to threatened morality, enabling people to truly wash away their sins. From abstract Who is audience? What question was explored? “Macbeth effect” Threats to moral purity Need to cleanse Increased mental accessibility of cleansing-related products Greater desire for cleansing products Greater likelihood of taking antiseptic wipes Who were participants? What were the participants’ characteristics? What measurements were taken? How often? From methods section Not in main text Look in Supplemental material Study 1 Participants. Sixty undergraduate students at Northwestern University participated in this study. Design and Procedure. Participants were randomly assigned to the cells of a 2-level single factor (Recall: ethical vs. unethical), between-participants design. They were led to separate breakout rooms upon arrival and were told that the researcher was interested in studying the differences in memories associated with ethical or unethical behaviors. In the ethical condition, participants were asked to describe in detail an ethical thing that they had done in the past and to describe any feelings or emotions they experienced. In the unethical condition, they were asked to describe an unethical deed and any emotions they experienced. This manipulation was adapted from a recall task in previous research (1). After the recall, participants engaged in a seemingly unrelated word completion task, in which they filled in blank spaces within word fragments to convert them into meaningful words. There were six word fragments, three of them (i.e., W _ _ H, SH _ _ ER, and S _ _ P) could be completed as either cleansing-related (i.e., wash, shower, and soap) or unrelated words (e.g., wish, shaker, and step). We summed the number of cleansing-related word fragments participants completed to form a composite measure of mental accessibility to cleansing-related concepts and submitted this measure to a one-way ANOVA. This measure and analysis have been used in many previous studies on mental accessibility (2, 3). Study 2 Participants. Twenty-seven undergraduate students at Northwestern University participated in this study. Design and Procedure. Participants were randomly assigned to the cells of a 2-level single factor (Prime: ethical versus unethical), between-participants design. They were led to individual breakout rooms upon arrival and engaged in multiple seemingly unrelated tasks. Instead of using the behavior recall task as in Study 1, we used an implicit manipulation for the ethical vs. unethical prime. In this manipulation, participants hand copied a short story written in the first person. They were told that the researcher was interested in studying the association between handwriting and personality. Participants in the ethical prime condition hand-copied the following story about an honest office worker: Two years ago, when I was a junior partner at a prestigious law firm, I was coming up for promotion against another junior partner, Chris. For several months, Chris had been working on a major case for the city that would make or break his career at the firm. However, he could not locate a key zoning document, without which, it was unlikely that he would have sufficient evidence to successfully argue his case. Late one evening, as I was rummaging through a corner filing cabinet, I happened to come across the zoning document that Chris was in desperate need of. I pulled it from the cabinet and placed it without a note on Chris’ desk, knowing that he would be so relieved when he arrived to work the next morning. Those in the unethical prime condition hand-copied the same story except that this time the office worker in the story decided to hide the critical document and sabotage the career of his or her competitor (the last sentence was replaced with, “I pulled it from the cabinet and walked over to the office shredder, knowing that my promotion would now be secured”). After completing the hand-copying task, participants engaged in a marketing task and rated the desirability of various products on a seven-point scale (1 = completely undesirable, 7 = completely desirable). Some of the products were cleansing products, including Dove shower soap, Crest toothpaste, Windex cleaner, Lysol disinfectant, and Tide detergent; other products included Post-it Notes, Nantucket Nectars juice, Energizer batteries, Sony CD cases, and Snickers bars. The desirability rating served as the dependent measure because participants who have a need for bodily cleansing should express greater desire towards cleansing related products. None of the participants suspected the link between the manipulation and the product rating task. Study 3 Participants. Thirty-two undergraduate students at Northwestern University participated in this study. Design and Procedure. Participants were randomly assigned to the cells of a 2-level single factor (Recall: ethical vs. unethical), between-participants design. They were led to individual breakout rooms upon arrival and engaged in the same memory recall task (i.e., the ethical vs. unethical recall) as in Study 1. They were then approached individually by the experimenter during the break and asked whether they would like to have an antiseptic cleansing wipe or an American pencil as a free gift (both items were visible in the experimenter’s hands). They were told that those materials were left over from a previous study and the experimenter would like to give them away as free gifts. Their choice between the pencil and wipe served as the dependent variable. The gifts were tested to make sure that they were equally desirable on an independent sample with 15 undergraduate students. These participants went through a similar but non-moral recall task (unrelated to ethics or cleanliness) and were then asked to choose between the wipes and pencils. Results confirmed equal desirability: 53% took the wipe and 47% took the pencil. Study 4 Participants. Forty-five undergraduate students at Northwestern University participated in this study. Design and Procedure. Participants were randomly assigned to the cells of a 2-level single factor (Intervention: cleansed vs. not-cleansed), between-participants design. They were led to separate breakout rooms upon arrival and told that they were going to engage in a computer task and a paper task. Participants were first asked to describe an unethical deed from their past via a computer program – the same task as in Study 1. They were then randomly assigned to one of two conditions. In the cleansed condition, participants were told that the Research Protection Board had recommended that we provide participants with hand-wipes after using public computers, and they were given an antiseptic cleansing wipe to use at that point. Those in the not-cleansed condition, however, were simply told that they had finished the computer task and could move on to the paper-based task. After the cleansing manipulation, participants in both conditions were given a paper-and-pencil task in which they assessed their current emotional state, including disgust, happiness, amusement, guilt, embarrassment, regret, calm, shame, confidence, excitement, distress, and anger. Finally, right before the end of the experiment, participants were solicited to volunteer to participate in a research study. They were told that a graduate student was looking for volunteers to help with one of her dissertation studies. The participation would be unpaid because the graduate student had no financial support yet desperately needed more data to complete her dissertation. Presumably, after participants recalled an unethical behavior from their past, they would be motivated to offer help to compensate for their wrongdoings. In contrast, participants who had cleansed their hands before being solicited for help would be less motivated to volunteer because the sanitation wipes had already washed away their moral stains and restored a suitable moral self. There are details about some additional analyses on Study 4 we do not excerpt here. From main text We first determined whether a threat to moral purity increases the mental accessibility of cleansing-related words. We asked participants to recall in detail either an ethical or unethical deed from their past and to describe any feelings or emotions they experienced. Then they engaged in a word completion task in which they converted word fragments into meaningful words. Of the six word fragments, three (W _ _ H, SH __ ER, and S __ P) could be completed as cleansing-related words (wash, shower, and soap) or as unrelated words (e.g., wish, shaker, and step). Participants who recalled an unethical deed generated more cleansing- related words than those who recalled an ethical deed [F(1,58) = 4.26, P = 0.04], suggesting that unethical behavior enhances the accessibility of cleansing-related concepts (Table 1). Figure 34: Table 1 from (Zhong and Liljenquist 2006) Erratum In the Report Washing away your sins: threatened morality and physical cleansing, the SEM values for Study 1 were entered incorrectly in Table 1. For the effect of ethical recall, the value should be 0.188, not 1.88, and for the effect of unethical recall, the value should be 0.177, not 1.77. The authors gratefully acknowledge A. Brouwer, S.A. Koppes, L. Wolters, L.D.J. Kuijper, and C. Zonneveld for pointing out this error. Study 2 investigated whether an implicit threat to moral purity produces a psychological desire for cleansing, through expressed preferences for cleansing products. Participants were told that we were investi- gating the relationship between handwriting and personality and were asked to hand-copy a short story written in the first person. The story described either an ethical, selfless deed (helping a co-worker) or an unethical act (sabotaging a co-worker) (9). Participants then rated the desirability of various products from 1 (completely undesirable) to 7 (completely desirable). Cleansing products included Dove shower soap, Crest toothpaste, Windex cleaner, Lysol disinfectant, and Tide detergent; other products included Post-it Notes, Nantucket Nectars juice, Energizer batteries, Sony CD cases, and Snickers bars. As expected, copying the unethical story increased the desirability of cleansing products as compared to copying the ethical story [F(1,25) = 6.99, P = 0.01], with no differ- ences between conditions for the noncleans- ing products [F(1,25) = 0.02, P = 0.89] (Fig. 1). Figure 35: Figure 1 from (Zhong and Liljenquist 2006) We sought to replicate the results of Study 2 using behavioral measures, so our next study examined the likelihood oftaking an antiseptic cleansing wipe after recalling an ethical or unethical deed. Participants engaged in the same recall task as in Study 1 and were then offered a free gift and given a choice between an antiseptic wipe and a pencil (verified in a control condition to be equally attractive offerings). Those who recalled an unethical deed were more likely to take the antiseptic wipe (67%) than were those who recalled an ethical deed (33%) (\\(\\chi^2\\) = 4.57, p = 0.03) (Table 1). In Study 4, participants described an unethical deed from their past (the same recall task as in Study 1). Afterwards, they either cleansed their hands with an antiseptic wipe or not. Then they completed a survey regarding their current emotional state (9). After completing the survey, participants were asked if they would volunteer without pay for another research study to help out a desperate graduate stu- dent. Presumably, participants who had cleansed their hands before being solicited for help would be less motivated to volunteer because the sanitation wipes had already washed away their moral stains and restored a suitable moral self. As predicted, physical cleansing significantly reduced volunteerism: 74% of those in the not-cleansed condition offered help, whereas only 41% of participants who had a chance to cleanse their hands offered to help (\\(\\chi^2\\)=5.02, P = 0.025). Thus, the direct compensatory behavior (i.e., volunteering) dropped by almost 50% when participants had a chance to physically cleanse after recalling an unethical behavior. (Earp et al. 2014) Earp, B. D., Everett, J. A. C., Madva, E. N. &amp; Hamlin, J. K. (2014). Out, Damned Spot: Can the “Macbeth Effect” Be Replicated? Basic and Applied Social Psychology, 36(1), 91–98. https://doi.org/10.1080/01973533.2013.856792 PSU Libraries link Zhong and Liljenquist (2006) reported evidence of a “Macbeth Effect” in social psychology: a threat to people’s moral purity leads them to seek, literally, to cleanse themselves. In an attempt to build upon these findings, we conducted a series of direct replications of Study 2 from Z&amp;L’s seminal report. We used Z&amp;L’s original materials and methods, investigated samples that were more representative of the general population, investigated samples from different countries and cultures, and substantially increased the power of our statistical tests. Despite multiple good-faith efforts, however, we were unable to detect a “Macbeth Effect” in any of our experiments. We discuss these findings in the context of recent concerns about replicability in the field of experimental social psychology. From abstract Type of paper: empirical|theoretical|review|opinion|empirical (partial replication) What question was explored? Who were participants? What were the participants’ characteristics? What measurements were taken? How often? From Study 1 method Participants in this study were 153 undergraduate students enrolled at a university in the United Kingdom. Participants were invited to take part via e-mail messages sent to departmental mailing lists and received a chocolate bar in exchange for their time. In Part 1, participants were randomly assigned to one of two priming conditions: ethical or unethical. In Part 2, participants rated a number of consumer products for their desirability on a scale of 1 to 7. In an attempt to prevent participants’ drawing any connections between Parts 1 and 2, they were told that Parts 1 and 2 were two separate experiments. Just as in Study 2 from Zhong and Liljenquist’s (2006) original report, participants were told they were taking part in an investigation into handwriting and personality and were asked to hand-copy a short story written in the first person. In the “unethical” condition, the paragraph described an unethical deed from the first-person perspective, as follows: Two years ago, when I was a junior partner at a prestigious law firm, I was coming up for promotion against another junior partner, Chris. For several months, Chris had been working on a major case for the city that would make or break his career at the firm. However, he could not locate a key zoning document, without which, it was unlikely that he would have sufficient evidence to successfully argue his case. Late one evening, as I was rummaging through a corner filing cabinet, I happened to come across the zoning document that Chris was in desperate need of. I pulled it from the cabinet and walked over to the office shredder, knowing that my promotion would now be secured. In the “ethical” condition, the paragraph was exactly the same, except that the last sentence read: I pulled it from the cabinet and placed it without a note on Chris’ desk, knowing that he would be so relieved when he arrived to work the next morning. Participants were then told that they were taking part in research looking at consumer marketing and were asked to rate the desirability of various products from 1 (completely undesirable) to 7 (completely desirable) and to say how much they would be willing to pay (£) for each product. The 10 items used were the exact same original items from Zhong and Liljenquist’s study, in their original order, with four items adapted slightly for a British sample by replacing unfamiliar American brands with equivalent British brands. The items and their order were specifically as follows: Post-it notes, Dove shower soap, Colgate toothpaste [Crest toothpaste in the original], pressed fruit juice 2 [Nanucket Nectars juice in the original], Energizer batteries, Sony CD cases, Windex glass cleaner, Dettoll disinfectant [Lysol countertop disinfectant in the original], Snickers candy bar, and Surf laundry detergent [Tide laundry detergent in the original]. Upon completion of the consumer products survey, participants were given a chocolate bar to compensate for their time and were thanked for their participation. From Study 1 results Independent samples t tests revealed no significant difference of condition on desirability of consumer product, t (151) = .03, p = .97, 95% CI [–0.29, 0.30], with no significant difference in the mean desirability of the cleansing items between the moral condition (M = 3.09) and immoral condition (M = 3.08). Similarly, there was no significant difference in how much participants were willing to pay for the consumer products, t (151) = − .28, p = .78, 95% CI [–0.36, 0.27], with comparable means in both the ethical condition (M = 2.19) and the unethical condition (M = 2.24). Looking at individual items, there were no significant effects of condition on the desirability of—or willingness to pay for—any individual cleansing item. From Study 2 method Participants. One hundred fifty-six American participants (83 female, M age = 33), using the Mechanical Turk (MTurk) online interface, participated in exchange for $.30. MTurk is a website that facilitates payment for the completion of tasks posted by researchers. Participant samples recruited through this service have been shown to be more representative of the general population than are student samples, and are known to yield reliable data (Buhrmester, Kwang, &amp; Gosling, 2011). Eight participants were excluded from analyses for failure to complete the questionnaires. Materials and procedure. As in Study 1, participants were randomly assigned to one of two priming conditions: ethical or unethical. All participants subsequently rated a number of consumer products for their desirability on a scale of 1 to 7, and noted how much they would be willing to pay ($) for each. To adapt the original priming materials from Zhong and Liljenquist for use in an online medium, the passages about helping/sabotaging a coworker were presented on participants’ computer screens with all of their punctuation removed. Participants were asked to retype the passage (rather than rewrite it, by hand, as in the original studies), inserting simple punctuation marks such as full stops (periods), commas, and capitalization where appropriate; participants could not advance to the next screen without performing this task, and all participants completed the priming task successfully. Although this design adjustment involved a slight departure from the rewriting task used in Zhong and Liljenquist’s original Study 2, we reasoned that our online-friendly prime might actually be more effective than the original. This is because to determine which punctuation marks were needed, participants would presumably have to process the meaning of the passage, whereas to hand-copy a passage exactly as it is written one could work by simple rote. After participants completed this punctuation priming task, they were shown a screen in which they were told that they were now taking part in research looking at consumer marketing. They were asked to rate the desirability of various products from 1 (completely undesirable) to 7 (completely desirable) and to say how much they would be willing to pay ($) for each product. The 10 items presented were the original items from Zhong and Liljenquist’s study, with no adjustments made to brand names, and were presented in their original order: Post-it notes, Dove shower soap, Crest toothpaste, Nanucket Nectars juice, Energizer batteries, Sony CD cases, Windex glass cleaner, Lysol countertop disinfectant, Snickers candy bar, and Tide laundry detergent. After completing the consumer products rating task, participants were shown a screen that thanked them for their efforts and were then directed to a link for claiming their small monetary reward. From Study 2 results Independent samples t tests revealed no significant difference of condition on desirability of the cleansing items, t(146) = − .79, p = .43, 95% CI [–0.62, 0.27] with comparable means in both the ethical (M = 4.23) and unethical (M = 4.41) conditions. Similarly, there was no significant difference in how much participants were willing to pay for the cleansing items, t(146) = .17, p = .87, 95% CI [–0.50, 0.59], with comparable means for both the ethical (M = 3.50) and unethical conditions (M = 3.46). Analyses were conducted on all individual cleansing items, and revealed no effect of condition on any individual item, with one exception: Consistent with predictions, a significant difference between conditions was found for how much participants were willing to pay for toothpaste, F (1, 146) = 4.76, p = .03, 95% CI [2.36, 3.03], with participants willing to pay more for the toothpaste in the unethical condition (M = 2.69) than in the ethical condition (M = 2.42). From Study 3 method Participants. Two hundred eighty-six Indian participants (92 female, M age = 31) using the MTurk online interface participated in exchange for $.30. Seventeen participants were excluded from analyses for failure to complete the questionnaires. Materials and procedure. The procedure was identical to that used in Study 2. Just as in Study 1, however, consumer product brand names had to be adjusted to accommodate a non-U.S. sample. In this case, brand names were replaced with generic descriptions of each product. Accordingly, participants were asked to rate their preferences concerning: sticky notes, shower soap, toothpaste, pressed fruit juice, batteries, CD cases, glass cleaner, countertop disinfectant, a candy bar, and laundry detergent. From Study 3 results Independent samples t tests revealed no significant difference of condition on either desirability, t(260) = − 1.83, p = .07, 95% CI [–0.42, 0.02] or how much participants were willing to pay, t(260) = − .29, p = .78, 95% CI [–1.37, 1.02]. The marginal effect found for desirability of cleansing items (p = .07, see earlier) was actually in the opposite direction to what Zhong and Liljenquist found in their original research: Indian participants in the unethical priming condition desired cleansing items (marginally) less (M = 5.25) than participants in the ethical priming condition (M = 5.46). There was no effect of condition on any individual item. Side-by-side comparisons Zhong et al. Study 2 Earp et al. Study 1 Earp et al. Study 2 Earp et al. Study 3 \\(n\\) 27 153 156 286 Country US UK US India Age group Undergraduate students Undergraduate students Adults Adults Setting in-person in-person online online Desirability of cleaning product: Ethical story 3.751 3.09 4.23 not reported Desirability of cleaning product: Unethical story 4.92 3.08 4.41 not reported Paper citations 15043 1004 References "],["bias.html", "Bias Read Exercise Kinds of bias Discuss p-hacking exercise", " Bias Read (Ritchie 2020), Chapter 4 Exercise P-hack your way to scientific glory Kinds of bias Discuss p-hacking exercise Who got a “significant” result? How many different analyses did you try? Who changed their analysis after finding a significant result? Did anyone try another analysis and keep the non-significant result? References "],["survey_01_results.html", "Survey 1 results Purpose Background Set-up Download data Clean data Visualize data", " Survey 1 results Purpose This document summarizes the analysis of data for Survey 1 on scientific norms and counter-norms (https://forms.gle/1zqzfNNXWyCgiDSJ9). This survey is part of the class discussion of adherence to norms and counternorms. Background The survey questions were derived from the Appendix in (Kardash and Edwards 2012). We thank these authors for publishing the survey questions in their article so that we could reuse them for our class. Set-up We load the required R packages. suppressPackageStartupMessages(library(&quot;tidyverse&quot;)) # for pipe %&gt;% suppressPackageStartupMessages(library(&quot;googledrive&quot;)) suppressPackageStartupMessages(library(&quot;magrittr&quot;)) suppressPackageStartupMessages(library(&quot;dplyr&quot;)) suppressPackageStartupMessages(library(&quot;ggplot2&quot;)) Download data Download the data file from the spreadsheet generated by the Google Form into a comma-separated value (CSV) file in a local directory called csv/. Authenticate to Google. googledrive::drive_auth(email = &quot;rick.o.gilmore@gmail.com&quot;) if (!dir.exists(&#39;csv&#39;)) { dir.create(&#39;csv&#39;) } csv_fn &lt;- &quot;csv/psych-490-2023-spring-survey-01.csv&quot; googledrive::drive_download(file = &#39;PSYCH 490.002 Survey 1 (Responses)&#39;, path = csv_fn, type = &#39;csv&#39;, overwrite = TRUE) ## File downloaded: ## • &#39;PSYCH 490.002 Survey 1 (Responses)&#39; ## &lt;id: 1ZbUBDdga_Njd-x2c14Gv5MBlTRX-rXOYGcpXvt0gh9A&gt; ## Saved locally as: ## • &#39;]8;;file:///Users/rick/rrr/psych-490-reproducibility-2023-spring-notes/src/csv/psych-490-2023-spring-survey-01.csvcsv/psych-490-2023-spring-survey-01.csv]8;;&#39; Clean data Load the data file. if (file.exists(csv_fn)) { survey_01 &lt;- readr::read_csv(csv_fn, show_col_types = FALSE) } else { message(&quot;File not found: &quot;, csv_fn) survey_01 &lt;- NULL } Examine the data set as a whole. str(survey_01) ## spc_tbl_ [21 × 10] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ Timestamp : chr [1:21] &quot;10/21/2022 16:07:25&quot; &quot;1/10/2023 11:48:53&quot; &quot;1/12/2023 11:43:32&quot; &quot;1/12/2023 11:43:54&quot; ... ## $ Scientists are generally motivated by the desire for knowledge and discovery, and not by the possibility of personal gain. : num [1:21] 3 4 3 3 3 4 3 3 5 3 ... ## $ Scientists make an attempt to consider all new evidence, hypotheses, theories, and innovations, even those that challenge or contradict their own work.: num [1:21] 2 2 3 4 3 4 2 2 5 3 ... ## $ Scientists generally assess new knowledge and its applications based on the reputation and past productivity of the individual or research group. : num [1:21] 4 3 4 3 4 4 3 4 4 4 ... ## $ Scientists openly share new findings with all colleagues. : num [1:21] 1 3 2 2 3 3 2 2 4 4 ... ## $ Scientists generally invest their careers in promoting their own most important findings, theories, or innovations. : num [1:21] 5 5 5 5 4 5 3 3 4 4 ... ## $ Scientists compete with others in the same field for funding and recognition of their achievements. : num [1:21] 2 5 4 2 5 4 4 4 3 5 ... ## $ Scientists generally evaluate research only on its merit (i.e., according to accepted standards of the field). : num [1:21] 4 4 3 4 3 2 3 4 2 3 ... ## $ Scientists emphasize the protection of their newest findings to ensure priority in publishing, patenting, or applications. : num [1:21] 2 4 4 1 5 3 4 4 4 5 ... ## $ If you wish to comment about the questions in this survey, you may do so here. You are not required to comment. : chr [1:21] &quot;Test&quot; NA NA NA ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. Timestamp = col_character(), ## .. `Scientists are generally motivated by the desire for knowledge and discovery, and not by the possibility of personal gain.` = col_double(), ## .. `Scientists make an attempt to consider all new evidence, hypotheses, theories, and innovations, even those that challenge or contradict their own work.` = col_double(), ## .. `Scientists generally assess new knowledge and its applications based on the reputation and past productivity of the individual or research group.` = col_double(), ## .. `Scientists openly share new findings with all colleagues.` = col_double(), ## .. `Scientists generally invest their careers in promoting their own most important findings, theories, or innovations.` = col_double(), ## .. `Scientists compete with others in the same field for funding and recognition of their achievements.` = col_double(), ## .. `Scientists generally evaluate research only on its merit (i.e., according to accepted standards of the field).` = col_double(), ## .. `Scientists emphasize the protection of their newest findings to ensure priority in publishing, patenting, or applications.` = col_double(), ## .. `If you wish to comment about the questions in this survey, you may do so here. You are not required to comment.` = col_character() ## .. ) ## - attr(*, &quot;problems&quot;)=&lt;externalptr&gt; Examine the variable names. if (is.null(survey_01)) { warning(&quot;Error loading data file&quot;) } else { names(survey_01) } ## [1] &quot;Timestamp&quot; ## [2] &quot;Scientists are generally motivated by the desire for knowledge and discovery, and not by the possibility of personal gain.&quot; ## [3] &quot;Scientists make an attempt to consider all new evidence, hypotheses, theories, and innovations, even those that challenge or contradict their own work.&quot; ## [4] &quot;Scientists generally assess new knowledge and its applications based on the reputation and past productivity of the individual or research group.&quot; ## [5] &quot;Scientists openly share new findings with all colleagues.&quot; ## [6] &quot;Scientists generally invest their careers in promoting their own most important findings, theories, or innovations.&quot; ## [7] &quot;Scientists compete with others in the same field for funding and recognition of their achievements.&quot; ## [8] &quot;Scientists generally evaluate research only on its merit (i.e., according to accepted standards of the field).&quot; ## [9] &quot;Scientists emphasize the protection of their newest findings to ensure priority in publishing, patenting, or applications.&quot; ## [10] &quot;If you wish to comment about the questions in this survey, you may do so here. You are not required to comment.&quot; These variable names are too long to be useful. Let’s look at the source publication (Kardash and Edwards 2012) to see if we can simplify them in a useful way. So, the Appendix labels each question with a short phrase and notes whether the concept is a norm (N) or counter-norm (CN). Let’s rename the variables using the single words. new_names &lt;- c( &quot;Timestamp&quot;, &quot;Disinterestedness&quot;, &quot;Organized Skepticism&quot;, &quot;Particularism&quot;, &quot;Communality&quot;, &quot;Organized Dogmatism&quot;, &quot;Self-interestedness&quot;, &quot;Universalism&quot;, &quot;Solitariness&quot;, &quot;Comments&quot; ) # Make new data frame with long and short names for reference survey_qs &lt;- tibble(q_long = names(survey_01), q_short = new_names) # Swap out old (long) names for new (short) names names(survey_01) &lt;- new_names These data are ‘wide’, meaning that there are multiple variables for each respondent. The data will be easier to visualize and analyze if we make the data ‘longer’. survey_01_long &lt;- survey_01 %&gt;% tidyr::pivot_longer(., !c(&#39;Timestamp&#39;, &#39;Comments&#39;), names_to = &quot;norm_counternorm&quot;, values_to = &quot;rating&quot;) We should indicate whether these are norms, and label them “N”, or counternorms, and label them “CN”. survey_01_long &lt;- survey_01_long %&gt;% dplyr::mutate(., type = if_else( norm_counternorm %in% c( &quot;Disinterestedness&quot;, &quot;Organized Skepticism&quot;, &quot;Communality&quot;, &quot;Universalism&quot; ), &quot;Norm&quot;, &quot;Counternorm&quot; )) Finally, there is a “test” set of responses that I used to test this data processing workflow. We should delete those responses since they are nonsensical–I just hit random buttons to make some data. survey_01_long_clean &lt;- survey_01_long %&gt;% dplyr::filter(., is.na(Comments)) Visualize data What participants were asked Perceptions of scientific practices The following statements reflect different values about how the scientific research community should function, according to studies of scientists’ work. Use the scale below to indicate the extent to which you personally feel it ACTUALLY REPRESENTS the behavior of most scientists. Source: Kardash, C. M. &amp; Edwards, O. V. (2012). Thinking and behaving like scientists: Perceptions of undergraduate science interns and their faculty mentors. Instructional Science, 40(6), 875–899. https://doi.org/10.1007/s11251-011-9195-0. survey_qs %&gt;% kableExtra::kable(., format=&#39;html&#39;) q_long q_short Timestamp Timestamp Scientists are generally motivated by the desire for knowledge and discovery, and not by the possibility of personal gain. Disinterestedness Scientists make an attempt to consider all new evidence, hypotheses, theories, and innovations, even those that challenge or contradict their own work. Organized Skepticism Scientists generally assess new knowledge and its applications based on the reputation and past productivity of the individual or research group. Particularism Scientists openly share new findings with all colleagues. Communality Scientists generally invest their careers in promoting their own most important findings, theories, or innovations. Organized Dogmatism Scientists compete with others in the same field for funding and recognition of their achievements. Self-interestedness Scientists generally evaluate research only on its merit (i.e., according to accepted standards of the field). Universalism Scientists emphasize the protection of their newest findings to ensure priority in publishing, patenting, or applications. Solitariness If you wish to comment about the questions in this survey, you may do so here. You are not required to comment. Comments Unique respondents There appear to be \\(n=\\) 21 respondents as of 2023-01-25 13:30:53. Rating distribution Remember, the rating scale was from 1: “not at all” to 5: “a great deal”. survey_01_long %&gt;% ggplot() + aes(norm_counternorm, rating, fill = type) + geom_violin() + geom_point(position = position_jitter(width = .07, height = .07), alpha = 0.5) + coord_flip() + ggtitle(&quot;Ratings of scientists&#39; adherence to norms and counternorms&quot;) + theme(legend.position = &quot;bottom&quot;) + theme(legend.title = element_blank()) survey_01_long %&gt;% ggplot() + aes(type, rating, fill = type) + geom_violin() + geom_point(position = position_jitter(width = .07, height = .07), alpha = 0.5) survey_01 %&gt;% dplyr::mutate(., n_cum = seq_along(Timestamp)) %&gt;% dplyr::mutate(., Timestamp = lubridate::mdy_hms(survey_01$Timestamp)) %&gt;% ggplot() + aes(Timestamp, n_cum) + geom_point() + geom_line() References "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
